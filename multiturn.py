from openai import AzureOpenAI
import yaml

##### load GPT #####
with open('openai_gpt.yaml') as f:
    config = yaml.safe_load(f)

api_version = config["config"]["api_version"]
azure_endpoint = config["config"]["azure_endpoint"]
api_key = config["config"]["api_key"]

client = AzureOpenAI(
    api_version = api_version,
    azure_endpoint = azure_endpoint,
    api_key = api_key
)  

##### load prompt #####
with open('classification.txt', encoding='utf-8') as file:
    clssf_prompt =  file.read()
    
with open('history.txt', encoding='utf-8') as file:
    hist_prompt =  file.read()

##### set user conversation state #####
conversation_state = {
    "collected_group": [],  # ìˆ˜ì§‘ëœ ê·¸ë£¹ ì •ë³´
    "collected_history" : [],  # ìˆ˜ì§‘ëœ ì´ë ¥ ì •ë³´ 
    "pending_question": None,  # ì¶”ê°€ ì§ˆë¬¸
    "task_completed": False  # ë¶„ë¥˜ ì™„ë£Œ ì—¬ë¶€
}

#################################################################
#                            ì·¨í–¥ ì¡°ì‚¬                            #
#################################################################
def generate_follow_up_question():
    ### ì¶”ê°€ ì§ˆë¬¸ì„ ìœ„í•œ í•¨ìˆ˜ 
    global conversation_state
    print("""GaekoğŸ¦ : ë„¤ê°€ ì¢‹ì•„í•˜ëŠ” í–¥ì— ëŒ€í•´ ì¡°ê¸ˆ ë” ì•Œë©´, ë„¤ê²Œ ì •ë§ ë”± ë§ëŠ” í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤„ ìˆ˜ ìˆì„ ê²ƒ ê°™ì•„!
ì¼ìƒìƒí™œì„ í•˜ë©´ì„œ ë„¤ê°€ ì¢‹ë‹¤ê³  ëŠê¼ˆë˜ ì•„ë¬´ ëƒ„ìƒˆë‚˜ ë‹¤ ë§í•´ì¤˜!ğŸ¤©
ì‹¬ì§€ì–´ ì§€í•˜ì£¼ì°¨ì¥ ëƒ„ìƒˆ, ì»¤í”¼í–¥, ê·¤ëƒ„ìƒˆ ì´ëŸ° ê²ƒë„ ê´œì°®ì•„ğŸ˜š""")
    
    user_input = input("UserğŸ§¸ : ")

    response = client.chat.completions.create(
        model="hatcheryOpenaiCanadaGPT4o",
        messages=[
            {"role": "system", "content": clssf_prompt},  # ìœ„ì˜ system ë©”ì‹œì§€ ê·¸ëŒ€ë¡œ
            {"role": "user", "content": f"<input>-'ì‚¬ìš©ì'ì˜ ì…ë ¥ : {user_input}</input>"}
        ]
    )
    extracted_groups = response.choices[0].message.content.strip("[]").replace("'", "").split(", ")

    # 2. ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥
    conversation_state["collected_group"].extend(extracted_groups)
    
    # conversation_state["task_completed"] = True
    # return classify_user_preference()


def classify_user_preference():
    # ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥
    unique_groups = list(set(conversation_state["collected_group"]))
    return print(f"UserğŸ§¸ê°€ ì¢‹ì•„í•˜ëŠ” í–¥ ê·¸ë£¹: {unique_groups}")

def process_user_group(user_input):
    global conversation_state
    ### ì²« ì§ˆë¬¸ì„ ìœ„í•œ í•¨ìˆ˜ 

    # 1. í˜„ì¬ ì…ë ¥ìœ¼ë¡œ ê·¸ë£¹ ì¶”ì¶œ
    response = client.chat.completions.create(
        model="hatcheryOpenaiCanadaGPT4o",
        messages=[
            {"role": "system", "content": clssf_prompt},  # ìœ„ì˜ system ë©”ì‹œì§€ ê·¸ëŒ€ë¡œ
            {"role": "user", "content": f"<input>-'ì‚¬ìš©ì'ì˜ ì…ë ¥ : {user_input}</input>"}
        ]
    )
    extracted_groups = response.choices[0].message.content.strip("[]").replace("'", "").split(", ")

    # 2. ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥
    conversation_state["collected_group"].extend(extracted_groups)

    # 3. ë¶€ì¡±í•œ ì •ë³´ íŒë‹¨
    if len(set(conversation_state["collected_group"])) < 3:  # ìµœì†Œ 3ê°œ ê·¸ë£¹ í•„ìš”
        conversation_state["pending_question"] = generate_follow_up_question()
        return conversation_state["pending_question"]
    else:
        conversation_state["task_completed"] = True
        return classify_user_preference()

##### first chat #####
print("""
GaekoğŸ¦ :
ì•ˆë…•!ğŸ¦ ë‚œ í–¥ìˆ˜ ì „ë¬¸ê°€ 'ê°œì½”'ë¼ê³  í•´! í‚í‚ğŸ¦ ë„¤ê°€ ë”± ì¢‹ì•„í•  í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì£¼ê¸° ìœ„í•´ ëª‡ê°€ì§€ ê°„ë‹¨í•œ ì§ˆë¬¸ì„ í•  ê±°ì•¼.
ë¨¼ì €, ë„Œ ì–´ë–¤ ëƒ„ìƒˆë¥¼ ì¢‹ì•„í•´?ğŸ¤”
ë‚˜ëŠ” í¬ê·¼í•œ ì‚´ëƒ„ìƒˆì™€ ì°»ìëƒ„ìƒˆë¥¼ ì¢‹ì•„í•´, ì¢€ ë” ì „ë¬¸ì ?ìœ¼ë¡œ ì´ì•¼ê¸°í•˜ë©´ ë¨¸ìŠ¤í¬ ê³„ì—´ê³¼ í™”ì´íŠ¸ í”Œë¡œëŸ´ í–¥ì„ ì¢‹ì•„í•˜ì§€ ã…ã…
ë‚˜ì²˜ëŸ¼, ë„¤ê°€ ì¢‹ì•„í•˜ëŠ” í–¥ì„ ììœ ë¡­ê²Œ ë§í•´ì¤˜!ğŸ¦
        """)

user_input = input("UserğŸ§¸ : ")

process_user_group(user_input)

#################################################################
#                            ê³¼ê±° ì´ë ¥                            #
#################################################################

def generate_follow_up_question_hist():
    ### ì¶”ê°€ ì§ˆë¬¸ì„ ìœ„í•œ í•¨ìˆ˜ 
    global conversation_state
    print("""GaekoğŸ¦ : 
ë„¤ ì·¨í–¥ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì •ë³´ê°€ ì¡°ê¸ˆ ë” í•„ìš”í•´!ğŸ¥¹
í˜¹ì‹œ ë„¤ê°€ ì¢‹ì•„í•˜ëŠ” êµ¬ì²´ì ì¸ í–¥ìˆ˜ë‚˜ ë¸Œëœë“œì— ëŒ€í•´ ì¡°ê¸ˆ ë” ì•Œë ¤ì¤„ ìˆ˜ ìˆì„ê¹Œ?
ê·¸ë ‡ë‹¤ë©´ ë‚´ê°€ ë„ˆì—ê²Œ ë” ì •í™•í•œ ì¶”ì²œì„ í•´ì¤„ ìˆ˜ ìˆì„ ê±°ì•¼! ğŸ¤“
""")
    
    user_input = input("UserğŸ§¸ : ")

    response = client.chat.completions.create(
        model="hatcheryOpenaiCanadaGPT4o",
        messages=[
            {"role": "system", "content": hist_prompt},  # ìœ„ì˜ system ë©”ì‹œì§€ ê·¸ëŒ€ë¡œ
            {"role": "user", "content": f"<input>-'ì‚¬ìš©ì'ì˜ ì…ë ¥ : {user_input}</input>"}
        ]
    )
    extracted_groups = response.choices[0].message.content.strip("[]").replace("'", "").split(", ")

    # 2. ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥
    conversation_state["collected_history"].append(extracted_groups)
    
    conversation_state["task_completed"] = True
    return classify_user_preference(), classify_user_history()

def classify_user_history():
    # ìˆ˜ì§‘ëœ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥
    unique_groups = list(conversation_state["collected_history"])
    return print(f"UserğŸ§¸ì˜ ì´ë ¥: {unique_groups}")


def process_user_input(user_input):
    global conversation_state
    # initialize state
    conversation_state["pending_question"] = None 
    conversation_state["task_completed"] = False
    
    ### ì²« ì§ˆë¬¸ì„ ìœ„í•œ í•¨ìˆ˜ 

    # 1. í˜„ì¬ ì…ë ¥ìœ¼ë¡œ ê·¸ë£¹ ì¶”ì¶œ
    response = client.chat.completions.create(
        model="hatcheryOpenaiCanadaGPT4o",
        messages=[
            {"role": "system", "content": hist_prompt},  # ìœ„ì˜ system ë©”ì‹œì§€ ê·¸ëŒ€ë¡œ
            {"role": "user", "content": f"<input>-'ì‚¬ìš©ì'ì˜ ì…ë ¥ : {user_input}</input>"}
        ]
    )
    extracted_groups = response.choices[0].message.content.strip("[]").replace("'", "").split(", ")

    # 2. ìˆ˜ì§‘ëœ ë°ì´í„° ì €ì¥
    conversation_state["collected_history"].append(extracted_groups)

    # 3. ë¶€ì¡±í•œ ì •ë³´ íŒë‹¨
    if len(conversation_state["collected_history"]) < 2:  # ìµœì†Œ 3ê°œ ê·¸ë£¹ í•„ìš”
        conversation_state["pending_question"] = generate_follow_up_question_hist()
        return conversation_state["pending_question"]
    else:
        conversation_state["task_completed"] = True
        return classify_user_preference(), classify_user_history()
    

print("""
GaekoğŸ¦ :
ì¢‹ì•˜ì–´! ë„¤ê°€ ì¢‹ì•„í•˜ëŠ” í–¥ì´ ì–´ë–¤ ëŠë‚Œì¸ì§€ ì•Œ ê²ƒ ê°™ì•„ ğŸ§
ìì„¸íˆ ë§í•´ì¤˜ì„œ ê³ ë§ˆì›ŒğŸ¦
""")

print("""
GaekoğŸ¦ :
ê·¸ëŸ¼ ì´ì œ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°ˆê²Œ!ğŸ¦ ì´ë²ˆì—” ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë¬¼ì–´ë³¼ê±°ì•¼.
í˜¹ì‹œ ì¢‹ì•„í•˜ëŠ” í–¥ìˆ˜ ë¸Œëœë“œë‚˜ íŠ¹ì • í–¥ìˆ˜ê°€ ìˆì–´?
ë§Œì•½ íŠ¹ë³„íˆ ì—†ë‹¤ë©´, ì˜ˆì „ì— ë„¤ê°€ ì‚¬ìš©í–ˆë˜ í–¥ìˆ˜ë¥¼ ë§í•´ì¤˜! 
í–¥ìˆ˜ ì´ë¦„ì´ë‚˜ ë¸Œëœë“œëª…ì´ ì •í™•í•˜ê²Œ ê¸°ì–µì´ ì•ˆ ë‚˜ë©´, ê·¸ëƒ¥ ëŒ€ê°• ìƒê°ë‚˜ëŠ”ëŒ€ë¡œ ë§í•´ì¤˜ë„ ë¼!ğŸ˜‹
ìŒ, ë‚´ ê²½ìš°ì—ëŠ” ìƒ¤ë„¬ ë ˆì  1957ì´ë‘ í†°í¬íŠ¸ í™”ì´íŠ¸ìŠ¤ì›¨ì´ë“œë¥¼ íŠ¹ë³„íˆ ì¢‹ì•„í•˜ê³ , ë”¥ë””í¬ ë¸Œëœë“œ í–¥ìˆ˜ëŠ” ë‹¤ ì¢‹ì•„ ã…ã…
ë„Œ ì–´ë•Œ?
""")

user_input = input("UserğŸ§¸ : ")

process_user_input(user_input)

print("""
GaekoğŸ¦ :
ì •ë§ ê³ ë§ˆì›Œ! ë„ˆì— ëŒ€í•´ ì”ëœ© ì•Œê²Œ ë˜ì—ˆìœ¼ë‹ˆ, ì´ì œ ë„¤ê°€ ì¢‹ì•„í• ë§Œí•œ í–¥ìˆ˜ë¥¼ ì¶”ì²œí•´ì¤„ê²Œ ğŸ˜
""")